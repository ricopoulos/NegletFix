# VR Rehabilitation Tasks for Hemispatial Neglect
## NeglectFix V0 - Evidence-Based Task Design

**Based on**: VR-Visual Exploration Therapy (VR-VET) protocols + hemianopia VR training studies
**Target**: Left-space awareness training, visual scanning, spatial attention
**Integration**: Closed-loop with EEG neurofeedback
**Date**: October 2025

---

## Design Principles

### Evidence-Based Approach ✅

**From research**:
1. **Ecological environments** (Topics in Stroke Rehab, 2020): Everyday-like VR (kitchen, living room) improves transfer to real-world function
2. **Visual exploration** (Frontiers, 2023): VR-VET with systematic left-scanning shows efficacy
3. **Multisensory integration** (J. NeuroEngineering, 2025): Audio + visual cues improve outcomes
4. **Progressive difficulty** (Multiple studies): Gradual increase in complexity promotes sustained engagement

### Core Mechanics

**Primary goal**: Train systematic scanning of left visual space

**Secondary goals**:
- Increase time spent attending to left side
- Build spatial memory for left-side locations
- Reduce rightward bias in exploration
- Enhance awareness through multimodal feedback

**Avoided pitfalls**:
- ❌ Abstract/gamified tasks (poor real-world transfer)
- ❌ Frustrating difficulty (high dropout rates)
- ❌ Passive viewing (active exploration required)
- ❌ Visual clutter (overwhelming for neglect patients)

---

## Task Progression Framework

### Level 1: Foundational Awareness (Sessions 1-6)
**Focus**: Discovering left space exists
**Environment**: Simple, familiar, calm
**Difficulty**: Very easy, high success rate

### Level 2: Active Exploration (Sessions 7-15)
**Focus**: Systematic left-scanning strategies
**Environment**: Moderate complexity
**Difficulty**: Moderate, adaptive challenge

### Level 3: Functional Application (Sessions 16+)
**Focus**: Real-world simulation tasks
**Environment**: Complex, dynamic
**Difficulty**: Challenging, transfer to daily life

---

## Task Catalog

## LEVEL 1 TASKS

### Task 1.1: "Kitchen Discovery"

**Environment**: Simple kitchen scene
- Counter on left and right
- 5-7 large objects (coffee mug, fruit bowl, cutting board)
- Soft, warm lighting
- Minimal visual complexity

**Objective**: Find and look at objects on left side

**Mechanics**:
1. Objects start dim/grey (low contrast)
2. When **EEG engagement + left gaze** → Object brightens and glows
3. Audio cue: "You found the coffee mug!" (spatial audio from left)
4. Counter: "3 of 5 objects discovered"

**Progression within task**:
- First 2 minutes: Only 2 objects on far left
- Minutes 3-5: Add 1 object center-left
- Minutes 6-10: All 5 objects, including near-center

**Success criterion**: Find all objects within 10 minutes

**Data logged**:
- Time to first left object
- Total objects discovered
- Time spent gazing left (% of session)
- Number of EEG+gaze reward triggers

---

### Task 1.2: "Bedroom Morning Routine"

**Environment**: Bedroom scene (bed, nightstand, dresser, window)
- Nightstand on left side of bed
- Dresser with mirror on left wall
- Window with curtains (left side)

**Objective**: Locate items needed for morning routine

**Mechanics**:
1. Verbal prompt: "Where are your glasses?" (on left nightstand)
2. Item pulses gently when gaze gets close
3. Engagement + gaze → Item fully appears with pleasant sound
4. Next item prompt appears

**Item sequence** (increasing leftward):
1. Phone (center-left on bed)
2. Glasses (left nightstand)
3. Watch (far left dresser)
4. Slippers (under bed, left side)

**Multisensory cues**:
- Visual: Subtle pulse/glow
- Audio: "Try looking left" if stuck for 30 seconds
- Spatial audio: Sound emanates from object location

**Success criterion**: Find 4/4 items within 12 minutes

---

### Task 1.3: "Living Room Exploration"

**Environment**: Cozy living room
- Couch, coffee table, bookshelf (left wall)
- TV (center), plant (left corner)
- Window view (left side)

**Objective**: Free exploration with reward discovery

**Mechanics**:
1. No specific goals - exploration for exploration's sake
2. **Left side** has 10+ "reward zones"
3. When EEG+gaze in reward zone → Environment enhances:
   - Sunlight streams through left window
   - Plant blooms/animates
   - Books on left shelf glow warmly
   - Soft music swells from left

**No time limit**: 15-minute session, progress = total reward zones discovered

**Purpose**: Low-pressure exposure to left-space richness

---

## LEVEL 2 TASKS

### Task 2.1: "Grocery Store Scanning"

**Environment**: Supermarket aisle
- Shelves on both sides (left + right)
- Products arranged at varying heights
- Shopping list provided

**Objective**: Find items on shopping list

**Mechanics**:
1. List appears (HUD): "Find: milk, bread, apples, cereal, coffee"
2. **50% of items on left shelves** (randomized placement)
3. Must use systematic scanning to locate items
4. EEG engagement → Items become slightly easier to spot (subtle highlight)
5. Pick item (gaze + trigger) → Checkmark on list

**Cognitive load**:
- Remember list (or toggle HUD on/off)
- Scan systematically (not random darting)
- Inhibit rightward bias

**Difficulty adaptation**:
- Easy: 3 items, 2 on left
- Medium: 5 items, 3 on left
- Hard: 7 items, 5 on left, plus distractors

**Time limit**: 5 minutes

---

### Task 2.2: "Park Bird Watching"

**Environment**: Outdoor park scene
- Trees, benches, pond
- 360° environment (must turn head fully left)

**Objective**: Spot birds that appear on left side

**Mechanics**:
1. Audio cue: Bird chirp from left spatial location
2. Bird appears briefly (3-5 seconds) on left side of scene
3. Must turn head AND engage EEG to "lock on" to bird
4. Successful lock → Bird detail appears (species name, beautiful animation)
5. Bird flies away if not spotted in time

**Attention training**:
- Requires both spatial orientation (head turn) AND mental engagement (EEG)
- Auditory-to-visual cross-modal attention
- Time pressure encourages alertness (beta training)

**Progression**:
- Level 1: Birds appear at 30° left, long duration (8 sec)
- Level 2: Birds appear at 60° left, medium duration (5 sec)
- Level 3: Birds appear at 90° left (far periphery), short duration (3 sec)

**Success criterion**: Spot 8/10 birds

---

### Task 2.3: "Art Gallery Memory"

**Environment**: Museum/gallery with paintings on walls
- 6 paintings on left wall
- 6 paintings on right wall
- Minimalist space, focus on art

**Objective**: Memory task requiring left-attention

**Mechanics**:
1. **Study phase** (3 minutes): Explore gallery, paintings briefly described
2. **Recall phase** (5 minutes): Questions appear
   - "Which painting had a blue boat?" → Must look left to find it
   - "What was in the top-left painting?" → Spatial memory

**Neurofeedback integration**:
- EEG engagement during study → Paintings more vibrant (better encoding)
- Low engagement → Paintings dim (poor memory formation)
- Teaches: "Left-attention improves learning"

**Difficulty**:
- Easy: 3 left paintings, simple recall
- Medium: 5 left paintings, spatial + content questions
- Hard: All 12 paintings, detailed recall, timed

---

## LEVEL 3 TASKS

### Task 3.1: "Navigation Challenge"

**Environment**: Multi-room apartment or building
- Must navigate from bedroom → kitchen → living room
- Key landmarks on left side of each room
- Doors/exits positioned leftward

**Objective**: Navigate without missing left-side cues

**Mechanics**:
1. Task: "Go to the kitchen and find the red folder"
2. Red folder is on left-side counter in kitchen
3. En route: Doorways require noticing left-mounted door handles
4. Obstacles placed to right → Must navigate leftward to avoid

**Real-world simulation**:
- Tests functional mobility
- Requires spatial updating (remembering left turns)
- Penalizes rightward-only navigation

**Engagement requirement**:
- EEG threshold higher for Level 3 tasks
- Without engagement → Left-side cues disappear entirely
- Simulates real-world consequence (missing information if not attending)

**Success criterion**: Complete navigation + find object < 8 minutes

---

### Task 3.2: "Cooking Simulation"

**Environment**: Kitchen with recipe task
- Ingredients on left counter
- Cooking tools (pan, spatula) on left
- Recipe displayed on left wall or left-mounted tablet

**Objective**: Prepare virtual meal following recipe

**Mechanics**:
1. Recipe: "Make scrambled eggs"
2. Steps require interacting with left-placed items:
   - Get eggs from left fridge
   - Use pan on left stovetop
   - Grab spatula from left drawer
3. EEG engagement → Items respond correctly
4. Low engagement → Clumsy interactions, items "slip" (feedback to re-engage)

**Functional training**:
- ADL (activities of daily living) practice
- Sequential task completion
- Left-space interaction required for success

**Complexity progression**:
- Simple: 3-step recipe (eggs)
- Medium: 5-step recipe (sandwich)
- Complex: 7-step recipe (salad), timed, multiple left-objects

---

### Task 3.3: "Street Crossing Safety"

**Environment**: Urban sidewalk + crosswalk
- Traffic approaching from left (oncoming lane)
- Pedestrian crossing scenario

**Objective**: Safely cross street by detecting left-approaching vehicles

**Mechanics**:
1. Stand at crosswalk
2. Must look left to check for cars (required in many countries!)
3. EEG engagement + left-gaze → Cars become audible
4. Without left-check → Car horn warns (safety feedback)
5. Successful crossing requires left-attention

**Real-world critical skill**:
- Directly addresses safety concern of neglect
- Potential real-life injury prevention
- High ecological validity

**Difficulty**:
- Easy: Slow traffic, obvious cues
- Medium: Moderate traffic, shorter gaps
- Hard: Busy traffic, must time crossing precisely

**Emotional relevance**: Trains survival-critical skill

---

## Task Customization

### Environmental Variables

**Lighting**:
- Bright (daytime) vs. dim (evening) → Affects visual saliency
- Left-side lighting boost to draw attention

**Contrast**:
- High contrast (easy detection)
- Low contrast (requires sustained attention)

**Clutter**:
- Sparse (minimal distractors)
- Dense (real-world complexity)

**Color**:
- Warm tones on left (inviting, pleasant)
- Cool tones on right (less salient)

### Audio Cues

**Direct prompts**:
- "Try looking left"
- "Something interesting is on your left"

**Spatial audio**:
- Sounds emanating from left-placed objects
- Birds chirping, phone ringing, music playing from left

**Feedback sounds**:
- Success: Pleasant chime, musical tones
- Encouragement: "Great job!", "You found it!"

**Ambient**:
- Binaural beats (optional, alpha/beta frequency support)

---

## Closed-Loop Integration

### EEG-VR Coupling

**Reward triggers**:
```
if (eeg_engagement > threshold AND head_yaw > 15°_left):
    activate_reward()
```

**Reward manifestations per task**:

| Task | Reward Type | Effect |
|------|------------|--------|
| Kitchen Discovery | Visual | Object brightens, glows warmly |
| Bedroom Routine | Audio-Visual | Item appears + pleasant sound |
| Living Room | Environmental | Sunlight, plant blooms, music |
| Grocery Scanning | Visual | Subtle highlight on target items |
| Bird Watching | Unlock | Bird detail, animation unlocked |
| Art Gallery | Enhancement | Paintings vivid, better memory encoding |
| Navigation | Guidance | Left-side cues visible |
| Cooking | Interaction | Items respond smoothly |
| Street Crossing | Safety | Audio warning, traffic awareness |

### Adaptive Difficulty

**Within-task adjustment**:
- Monitor success rate every 2 minutes
- If < 30% success → Increase cues, lower threshold
- If > 70% success → Reduce cues, raise threshold

**Between-task progression**:
- Track overall performance across sessions
- Auto-advance to next level when criteria met:
  - Level 1 → 2: 80% success on all L1 tasks
  - Level 2 → 3: 70% success on all L2 tasks

---

## Engagement Hooks

### Intrinsic Motivation

**Mastery**: Clear progress, skill improvement visible
**Autonomy**: Choose which task to practice (within level)
**Purpose**: Direct relevance to real-life function

### Extrinsic Motivation (Optional)

**Progress dashboard**:
- Tasks completed
- EEG engagement trends (improving over time)
- Left-gaze % increasing

**Achievements** (gamification, use sparingly):
- "Explorer": Discovered all objects in Kitchen
- "Bird Watcher": Perfect score on Park task
- "Safety First": Completed Street Crossing without warnings

### Aesthetic Appeal

**Visual quality**:
- Warm, inviting environments
- NOT sterile clinical settings
- Comfortable, familiar spaces

**Sound design**:
- Calming ambient tracks
- Pleasant reward sounds (not jarring)
- Spatial audio for immersion

---

## Data Collection Per Task

### Performance Metrics

**Spatial behavior**:
- Head yaw distribution (histogram: left vs. right)
- Time to first left-gaze (latency)
- Number of left objects discovered vs. missed
- Spatial memory accuracy (recall tasks)

**Neurofeedback**:
- Reward trigger count
- Average engagement score
- % time above threshold
- Correlation between EEG and gaze

**Task completion**:
- Success/failure (binary)
- Time to complete
- Errors made (e.g., missed items, wrong items)

### Qualitative Feedback (Post-Session)

**Subjective questions**:
1. How difficult was this task? (1-5 scale)
2. Did you notice the left side more than usual?
3. Any strategies that helped you remember to look left?
4. Comfort level (VR sickness, fatigue)

---

## Safety & Accessibility

### VR Comfort

**Motion sickness prevention**:
- Stationary or slow-moving viewpoints (no rapid locomotion)
- Snap-turning disabled (smooth turn only, or roomscale)
- Frequent breaks encouraged

**Visual comfort**:
- Adjustable brightness
- No flashing/strobing effects
- High frame rate (90 Hz minimum)

### Cognitive Load Management

**Start simple**:
- Level 1 tasks very easy, build confidence
- Avoid frustration (negative affect counterproductive)

**Clear instructions**:
- Brief tutorial before each new task
- Visual + audio instruction delivery
- Option to repeat instructions

### Alternative Modalities

**For hearing-impaired**:
- Visual-only cues (no critical audio-only information)
- Captions for verbal prompts

**For severe neglect**:
- Extra cues (arrows pointing left)
- Extended time limits
- Partner mode (therapist can assist remotely)

---

## Technical Implementation Notes

### Unity Scene Structure

```
Scenes/
├── Level1_KitchenDiscovery.unity
├── Level1_BedroomRoutine.unity
├── Level1_LivingRoom.unity
├── Level2_GroceryStore.unity
├── Level2_ParkBirdWatching.unity
├── Level2_ArtGallery.unity
├── Level3_Navigation.unity
├── Level3_CookingSimulation.unity
└── Level3_StreetCrossing.unity
```

### Prefabs

- **RewardZone**: Trigger volume that activates on EEG+gaze
- **HighlightableObject**: Object with glow/brighten effect
- **AudioCue**: Spatial audio source component
- **ProgressTracker**: UI element showing completion %

### Scripts (C#)

- `TaskManager.cs`: Controls task flow, timing, success criteria
- `RewardController.cs`: Listens for EEG+gaze events, triggers rewards
- `GazeDetector.cs`: Analyzes head yaw, determines left-gaze
- `ObjectManager.cs`: Handles object visibility, highlighting
- `DataLogger.cs`: Logs all performance + EEG data to CSV

---

## Research Validation

### Evidence Supporting These Tasks

**Ecological environments** ✅
> "Cognitive training in an everyday-like virtual reality enhances visual-spatial memory capacities in stroke survivors with visual field defects" (Topics in Stroke Rehab, 2020)

**Visual exploration** ✅
> "VR-based Visual Exploration Therapy (VR-VET) demonstrates efficacy in hemispatial neglect rehabilitation" (Frontiers, 2023)

**Multisensory cues** ✅
> "Telerehabilitation for visual field defects with multisensory training shows feasibility and effectiveness" (J. NeuroEngineering, 2025)

**Real-world transfer** ✅
> "VR training improves particularly visual-spatial skills in patients with hemianopia" (Multiple studies)

**Closed-loop neurofeedback** ✅
> "Real-time closed-loop feedback more effective than open-loop for stroke BCI rehabilitation" (REINVENT, 2019)

---

## Next Steps: Implementation Priority

### Phase 1: Prototype (Build First)
1. **Task 1.1: Kitchen Discovery** (simplest, foundational)
2. Basic EEG trigger integration
3. Data logging framework

### Phase 2: Expansion
4. **Task 1.3: Living Room** (free exploration validation)
5. **Task 2.1: Grocery Store** (add complexity)

### Phase 3: Full Suite
6. Remaining tasks (as time permits)
7. Difficulty adaptation algorithms
8. Progress dashboard

---

**Document version**: 1.0
**Last updated**: October 19, 2025
**Status**: Ready for Unity implementation
